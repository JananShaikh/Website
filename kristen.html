<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>SABC News Audio Transcription</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="img/favicon.png" rel="icon">
  <link href="img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="vendor/aos/aos.css" rel="stylesheet">
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="style.css" rel="stylesheet">

  <!-- =======================================================
  * Template Name: Ninestars
  * Updated: Sep 18 2023 with Bootstrap v5.3.2
  * Template URL: https://bootstrapmade.com/ninestars-free-bootstrap-3-theme-for-creative/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top d-flex align-items-center">
    <div class="container d-flex align-items-center justify-content-between">

      <div class="logo">
        <h1 class="text-light"><a href="index.html"><span>SABC2TXT</span></a></h1>
        <!-- Uncomment below if you prefer to use an image logo -->
        <!-- <a href="index.html"><img src="img/logo.png" alt="" class="img-fluid"></a>-->
      </div>

      <nav id="navbar" class="navbar">
        <ul>
          <li><a class="nav-link scrollto" href="#abstract">Abstract</a></li>
          <li><a class="nav-link scrollto" href="#methodology">Methods</a></li>
          <li><a class="nav-link scrollto" href="#results">Results</a></li>
          <li><a class="nav-link scrollto" href="#footer">Conclusions</a></li>
        </ul>
        <i class="bi bi-list mobile-nav-toggle"></i>
      </nav><!-- .navbar -->

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs Section ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Project Details</h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li>SABC News Audio Transcription</li>
          </ol>
        </div>

      </div>
    </section><!-- Breadcrumbs Section -->

    <!-- =======  Abstract Section ======= -->
    <section id="abstract" class="abstract">
      <div class="container">
        <div class="abstract-description">
          <h2>Abstract</h2>
          <p>
            The lack of electronic linguistic resources in the southern Nguni
            languages, such as isiXhosa, negatively impacts computational and
            statistical systems that rely on these resources. Transcribing these
            languages would facilitate text-based research experiments and
            support multiple areas of natural language processing (NLP). This
            paper describes the methods used to create an isiXhosa automatic
            speech recognition (ASR) transcription system using the
            CMUSphinx speech recognition toolkit for South African
            Broadcasting Corporation (SABC) news. The accuracy of this
            system is evaluated by using metrics such as word error rate
            (WER), and the Levenshtein distance at the character and word
            level. Multiple experiments were conducted using a gold standard
            test corpus of approximately 40 minutes of SABC news and 3 hours
            of test audio provided by the South African Centre for Digital
            Language Resources (SADiLaR) website. The experiments done
            on the SABC news audio showed that the Levenshtein distances for
            the news anchor in the field were more accurate than the main news
            anchor and the distances for male speakers were more accurate than
            for females. Although Pocketsphinx performed better than Sphinx4
            overall, both systems performed poorly on the SABC news audio,
            each with a WER of 100%. In comparison, the SADiLaR test audio
            had a WER of 39% for Pocketsphinx and 65% for Sphinx4.</p>
        </div>
      </div>
    </section><!-- End Abstract Section -->

    <!-- =======  Methodology Section ======= -->
    <section id="methodology" class="methodology">
      <div class="container">

    
            <div class="methodology-description">
              <h2>Methods</h2>
              <p>The process involves building a language model and an acoustic model, audio segmentation, and evaluating the accuracy of two different speech recognition tools: Pocketsphinx and Sphinx4.</p>
              <h4>1. Building a Language Model</h4>
              <p>
                Datasets were obtained from the South African Centre for Digital Language Resources (SADiLaR). Building the language model was the first step, accomplished using the CMU Language Model Toolkit (CMULMTK) and data preparation. Language model training involved generating vocabulary and 'idngram' files, as well as converting the language model into 'arpa' and binary formats for compatibility with Sphinxtrain and CMUSphinx (Pocketsphinx and Sphinx4).
              </p>
              <h4>2. Building an Acoustic Model</h4>
              <p>To train the model, a specific file system structure was required, containing all the necessary files: language model, and phonetic and filler dictionaries.
              Data preparation for the acoustic model included creating the necessary file structure and organising the necessary data within this structure.
              Data pre-processing involved converting the raw text-to-speech datasets into a format expected by Sphinxtrain.
              The phonetic dictionary was initially incomplete, so a grapheme-to-phoneme (G2P) model was trained to complete it. 
              Training on sphinxtrain, ran for a few hours, achieving a Word Error Rate (WER) of 30.9% and a Sentence Error Rate (SER) of 34.9% when tested with data from the NCHLT corpus.
              </p>
              <h4>3. Audio Segmentation and File Processing:</h4>
              <p>Audio segmentation was carried out using Python scripts and libraries like numpy and soundfile. The segmentation was based on the energy level of the speech, aiming to split the audio at points of low energy. However, manual segmentation was still required in cases where clear pauses were not detected. This manual intervention involved dividing longer segments and joining shorter ones that split mid-word to ensure a smoother flow. Once segmentation was completed, the source transcription files from the SABC news corpus were cleaned by converting all text to lowercase and removing punctuation. The cleaned text was organized with each audio segment's speech on a new line, facilitating a line-by-line comparison with hypothesis transcriptions to calculate transcription accuracy metrics.</p>
              <h4>4. System Development and Implementation</h4>
              <p>
                The system development and implementation involved the use of two speech recognition libraries, Pocketsphinx and Sphinx4. These were used for developing audio transcription systems, with Pocketsphinx implemented in Python and Sphinx4 in Java. The systems aimed to transcribe segmented audio files accurately.
              </p>
              <h4>5. Evaluation Metrics</h4>
              <p>Word Error Rate (WER) and Levenshtein distance (LD) were used to evaluate the accuracy of the transcriptions.
              </p>
              <h5>Word Error Rate</h5>
              <p><br>\[ \text{WER} = \frac{\text{substitutions} + \text{deletions} + \text{insertions}}{\text{total number of words}} \] </p>
               <h5>Levenshtein Distance</h5> 
               <p>\[ \text{LD} = \text{substitutions} + \text{deletions} + \text{insertions} \]</p>

               <h4>Experimental Setup</h4>
               <ul>
                <li>Experiments involved transcribing and evaluating test data and SABC news data.</li>
                <li>Comparisons were made between Pocketsphinx and Sphinx4, male and female and speech types.</li>
              </ul>
            </div>
          </div>

      </div>
    </section><!-- End Methodology Section -->
    
     <!-- =======  Results Section ======= -->
    <section id="results" class="results">
      <div class="container">
      
    
            <div class="results-description">
              <h2>Results</h2>
              <p>
                The results indicate that Pocketsphinx outperforms Sphinx4 on familiar data, but both perform equally on unfamiliar data. This might be due to the lack of maintenance for Sphinx4 by CMUSphinx. Overall, CMUSphinx performed poorly in transcribing isiXhosa SABC broadcast news, possibly due to small training datasets, short audio segments, and differences in speaker speed between training and test data. Not handling out-of-vocabulary (OOV) words could also affect the system's performance. Male speech segments performed better than female segments, likely due to pitch differences. Interestingly, field news speech sections performed better than main news anchor sections, possibly due to slower and clearer speech. Improving isiXhosa SABC news transcription would require a substantial amount of related training data, and exploring other toolkits and deep neural networks may be beneficial.
              </p>
              <div class="image-container" style="display: flex; justify-content: space-between;">  
                <div class="image">
                <figure>
         <img src="img/kristen/Female&Male_word.png" alt="" class="figure-image">
         <figcaption><strong> Figure 1: Levenshtein word distance for male and female speakers</strong></figcaption>
                </figure>
                </div>

                <div class="image">
                  <figure>
           <img src="img/kristen/Types_word.png" alt="" class="figure-image">
           <figcaption><strong> Figure 2: Levenshtein word distance for different types of speech</strong> </figcaption>
                  </figure>
                  </div>

            </div>
            <div class="image-container" style="display: flex; justify-content: space-between;">
            <div class="image">
              <figure>
       <img src="img/kristen/PSvsS4.png" alt="" width="70%" height="auto" style="border: 2px solid black;">
       <figcaption ><strong> Figure 3: Word Error Rate for Sphinx4 and Pocketsphinx</strong></figcaption>
              </figure>
              </div>
            </div>

      </div>
    </section><!-- End Results Section -->

    <section id="conclusions" class="conclusions">
        <div class="container">
          <div class="conclusions-description">
              <h2>Conclusions</h2>
              <p>Although the experimental results showed that Pocketsphinx’s
                WER for the NCHLT test data was 39% in comparison to Sphinx4
                with 65%, both systems performed poorly on the SABC news,
                unseen data, with a WER of 100%. Furthermore, when comparing
                male and female speakers it was seen that both systems performed
                better on male speech than female. Moreover, the field news had
                the best results amongst the different types of speech, with a better
                result than the main news anchor sections. The standard deviation
                for all the results showed a large variability between the data
                indicating that the data was widely spread out and not clustered
                close to the mean. Overall, the results show that CMUSphinx
                (Pocketsphinx and Sphinx4) does not perform accurately for
                isiXhosa SABC news.
              </p>
        </div>
      </div>
      </section>
      

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <section id="footer" class="footer">
    <div class="footer-newsletter">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-lg-6">
            <p><img src="img/uct.png" alt="" style="width: 5vw; height: auto;">
              © 2023 Research by Kristen Basson 
              <img src="img/cs.png" alt="" style="width: 5vw; height: auto;">
              <br> Email: bsskri003@myuct.ac.za
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
   
<!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="vendor/aos/aos.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="vendor/glightbox/js/glightbox.min.js"></script>
  <script src="vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="vendor/swiper/swiper-bundle.min.js"></script>
  <script src="vendor/php-email-form/validate.js"></script>

  <!-- Template Main JS File -->
  <script src="main.js"></script>

  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

</body>

</html>
